{"cells":[{"cell_type":"code","source":"import os\nimport random\nimport zipfile\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport tensorflow_model_optimization as tfmot\n\n\nfrom time import time\nfrom glob import glob\nfrom preprocessing import compute_linear_matrix, get_mfccs_training, get_mfcc, LABELS\nfrom itertools import product\nfrom functools import partial\nfrom typing import Iterable, Any\n\nseed = 42\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\nrandom.seed(seed)\ntf.random.set_seed(seed)\nnp.random.seed(seed)\n\n\nSAVING_FOLDER = os.path.join('.', 'SAVING_FOLDER')\n\nif not os.path.exists(SAVING_FOLDER):\n    os.makedirs(SAVING_FOLDER)\n","metadata":{"tags":[],"cell_id":"906499613b5047818548a885a6dc1bcd","source_hash":"26698be5","execution_start":1671616970092,"execution_millis":5155,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"2022-12-21 10:02:50.101126: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-21 10:02:50.312148: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2022-12-21 10:02:50.317212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2022-12-21 10:02:50.317233: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2022-12-21 10:02:50.344096: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2022-12-21 10:02:51.923388: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2022-12-21 10:02:51.923458: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2022-12-21 10:02:51.923464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train_ds_pure = tf.data.Dataset.list_files(['msc-train/go*', 'msc-train/stop*'])\nval_ds_pure = tf.data.Dataset.list_files(['msc-val/go*', 'msc-val/stop*'])\ntest_ds_pure = tf.data.Dataset.list_files(['msc-test/go*', 'msc-test/stop*'])","metadata":{"tags":[],"cell_id":"8aa83659a66f4870b7a30e7ba53c5789","source_hash":"de4cb657","execution_start":1671616975271,"execution_millis":454,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"2022-12-21 10:02:55.250096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2022-12-21 10:02:55.250125: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2022-12-21 10:02:55.250144: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-da3e1e27-78dd-422e-a631-d2ca46001cf1): /proc/driver/nvidia/version does not exist\n2022-12-21 10:02:55.250555: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def preprocess(filename):\n    signal, label = get_frozen_spectrogram(filename)\n    signal.set_shape(SHAPE)\n    signal = tf.expand_dims(signal, -1)\n    signal = tf.image.resize(signal, [32,32])\n    label_id = tf.argmax(label == LABELS)\n\n    return signal, label_id\n\ndef get_model(alpha, model_filter, input_shape):\n    '''Returns the model'''\n    return tf.keras.Sequential([\n        tf.keras.layers.Input(shape=input_shape),\n        tf.keras.layers.Conv2D(filters=int(model_filter * alpha), kernel_size=[3, 3], strides=[2, 2], use_bias=False, padding='valid'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.Conv2D(filters=int(model_filter * alpha), kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.Conv2D(filters=int(model_filter * alpha), kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(units=len(LABELS)),\n        tf.keras.layers.Softmax()\n    ])\n    return \n\ndef save_model(model, path):\n    '''Saves the model'''\n    if not os.path.exists(path):\n        os.makedirs(path)\n    model.save(path)\n\ndef convert_model(model, model_path, tflite_path, model_name):\n    '''Converts the saved model into tflite model and saves it (also zip version)'''\n    converter = tf.lite.TFLiteConverter.from_saved_model(model_path)\n    tflite_model = converter.convert()\n\n    if not os.path.exists(tflite_path):\n        os.makedirs(tflite_path)\n    tflite_model_path = os.path.join(tflite_path, f'{model_name}.tflite')\n\n    with open(tflite_model_path, 'wb') as fp:\n        fp.write(tflite_model)\n\n    with zipfile.ZipFile(f'{tflite_model_path}.zip', 'w', compression=zipfile.ZIP_DEFLATED) as f:\n        f.write(tflite_model_path, 'model10.tflite')\n    \n    sizes = {\n        'tflite_model_size' : os.path.getsize(f'{tflite_model_path}') / 1024.0,\n        'tflite_zip_model_size' : os.path.getsize(f'{tflite_model_path}.zip') / 1024.0\n    }\n\n    return tflite_model_path, sizes\n\ndef save_results(name, parameters, model_accuracies, sizes):\n    '''saves results in a csv'''\n    output_dict = {\n                    'model_name': name,\n                    **parameters,\n                    **model_accuracies,\n                    **sizes\n            }\n            \n    df = pd.DataFrame([output_dict])\n    output_path = os.path.join(SAVING_FOLDER, 'results.csv')\n    df.to_csv(output_path, mode='a', header = not os.path.exists(output_path), index = False)\n\n    \n        \n","metadata":{"tags":[],"cell_id":"35f2a751178842ee9412606eb72f8551","source_hash":"cc874b99","execution_start":1671616975735,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def training(downsampling_rate, frame_length_in_s, frame_step_in_s, num_mel_bins, num_coefficients, lower_frequency,\n upper_frequency, batch_size, initial_learning_rate, end_learning_rate, epochs, model_filter, alpha, initial_sparsity,\n final_sparsity):\n\n    # ******************* Parameter definition ***********************************************************\n    PREPROCESSING_ARGS = {\n        'downsampling_rate': downsampling_rate,\n        'frame_length_in_s': frame_length_in_s,\n        'frame_step_in_s': frame_step_in_s, \n        'num_mel_bins': num_mel_bins,\n        'num_coefficients': num_coefficients,\n        'lower_frequency': lower_frequency,\n        'upper_frequency': upper_frequency,\n    }\n    \n    # ******************* Preprocessing ***********************************************************\n    global SHAPE, get_frozen_spectrogram\n\n    get_frozen_spectrogram = partial(get_mfccs_training, **PREPROCESSING_ARGS)\n\n    for mfcc, label in train_ds_pure.map(get_frozen_spectrogram).take(1):\n        SHAPE = mfcc[:num_coefficients].shape\n\n\n    train_ds = train_ds_pure.map(preprocess).batch(batch_size).cache()\n    val_ds = val_ds_pure.map(preprocess).batch(batch_size)\n    test_ds = test_ds_pure.map(preprocess).batch(batch_size)\n\n    #get shape for model input\n    for example_batch, example_labels in train_ds.take(1):\n        input_shape = example_batch.shape[1:]\n\n\n\n    # ******************* Model And Training *******************************************************\n    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\n    metrics = [tf.metrics.SparseCategoricalAccuracy()]\n    callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n\n    linear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n        initial_learning_rate=initial_learning_rate,\n        end_learning_rate=end_learning_rate,\n        decay_steps=len(train_ds) * epochs,\n    )\n\n    optimizer = tf.optimizers.Adam(learning_rate=linear_decay)\n\n    begin_step = int(len(train_ds_pure) * epochs * 0.2)\n    end_step = int(len(train_ds_pure) * epochs)\n\n    # Pruning\n    pruning_params = {\n        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n            initial_sparsity= initial_sparsity,\n            final_sparsity= final_sparsity,\n            begin_step=begin_step,\n            end_step=end_step\n        )\n    }\n\n\n    model = tfmot.sparsity.keras.prune_low_magnitude(get_model(alpha, model_filter, input_shape), **pruning_params)\n    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n    history = model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)\n\n\n    # ******************* Results ***************************************************************\n    _, test_accuracy = model.evaluate(test_ds)\n    _, training_accuracy = model.evaluate(train_ds)\n    _, validation_accuracy = model.evaluate(val_ds)\n\n    accuracies = {\n        'training_accuracy_tf': training_accuracy*100,\n        'validation_accuracy_tf': validation_accuracy*100,\n        'test_accuracy_tf': test_accuracy*100\n    }\n\n    fig = plt.figure()\n    plt.plot(history.history['loss'], c='r')\n    plt.plot(history.history['val_loss'], c='b')\n    plt.title(f\"Training and Validation Loss\")\n    plt.legend(['train_loss', 'val_loss'])\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.show()\n\n    return model, accuracies\n\n","metadata":{"tags":[],"cell_id":"55aef3a0ac2f4ab1a418e40fedb9e289","source_hash":"a9eac503","execution_start":1671616975741,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"ARGUMENTS = {\n        'downsampling_rate': 16000,\n        'frame_length_in_s': 0.016,\n        'frame_step_in_s': 0.016,\n        'num_mel_bins': 20,\n        'num_coefficients': 20,\n        'lower_frequency': 20,\n        'upper_frequency': 8000,\n        'batch_size': 20,\n        'initial_learning_rate': 0.01,\n        'end_learning_rate': 1.e-5,\n        'epochs': 20,\n        'model_filter': 64,\n        'alpha': 0.2,\n        'initial_sparsity': 0.2,\n        'final_sparsity': 0.6,\n    }\n","metadata":{"tags":[],"cell_id":"de78dd3c3ed544208837f6e6cbac7880","source_hash":"811c6eda","execution_start":1671616975747,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model, accuracies = training(**ARGUMENTS)\n\nMODEL_NAME = 'model10'\nMODEL_PATH = os.path.join(SAVING_FOLDER, 'model', f'{MODEL_NAME}')\nsave_model(model, MODEL_PATH)\n\nTFLITE_PATH = os.path.join(SAVING_FOLDER, 'tflite_model')\nTFLITE_NAME, sizes = convert_model(model, MODEL_PATH, TFLITE_PATH, MODEL_NAME)\n\nsave_results(MODEL_NAME, ARGUMENTS, accuracies, sizes)\n","metadata":{"tags":[],"cell_id":"5fef3c37d01b4ebf8e73774ea6c3e15f","source_hash":"4568c13c","output_cleared":true,"execution_start":1671616975753,"execution_millis":62499,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=da3e1e27-78dd-422e-a631-d2ca46001cf1' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"1fc3aca8fc444942a9882f960f2cde28","deepnote_execution_queue":[]}}